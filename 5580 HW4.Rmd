---
title: "SpamDetection"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ModelMetrics)
library(caret)
library(pROC)
```

### Loading Data
```{r spam}
load("spam.RData")
```

### Creating Training and Testing set
```{r}
training <- dat[train,]
testing <- dat[!train,]
```

# Model A (Logistic Regression)
```{r}
## Fit the model with all features
modelA1 <- glm(spam~.,data = training, family = 'binomial')
```
## Decide Relevant features
```{r}

ImpVar <- varImp(modelA1)
remove_features <- rownames(head(ImpVar[order(ImpVar$Overall), ,drop = FALSE], n= 12))
# features to remove
print(remove_features)
```
## Check for outliers
```{r}
plot(resid(modelA1))
```

## Fit the Model with selected features and predict on testing set
```{r}
# fit the model
formula <- as.formula(paste('spam ~ . -',paste(remove_features,collapse = '-',sep = ''), sep = ''))
modelA2 <- glm(formula,data = training, family = 'binomial')

## Use the fitted model to predict - classification probability 0.5
predictA <- predict(modelA2,testing, type = 'response')
testing$predict_ModelA <- ifelse(predictA>0.5,1,0)
```

## Model A Diagnostics
### Sensitivity vs Specificity
```{r}
# Create Confusion Matrix
conf_mat <- as.matrix(table(Actual = testing$spam, Predicted = testing$predict_ModelA))
print(conf_mat)
# Sensitivity vs Specificity
print(paste('The specificity of model A is:',caret::precision(conf_mat)))
print(paste('The sensitivity of model A is:',caret::recall(conf_mat)))
```

### Plot ROC Curve for Model A and deterimine AUC
```{r}
plot(roc(testing$spam, predictA, direction = '<'), col = 'red', lwd = 3, main = 'ROC curve for Model A', print.auc = T)
```


## Select best threshold for Model A - Where sensitivity and specifictiy lines intersect
```{r}
sen_spec <- data.frame(x = seq(0.2,0.8,by = 0.05))
sen <- data.frame()
spec <- data.frame()
for (i in seq(0.2,0.8,by = 0.05)){
  ## Use the fitted model to predict
  testing$predict_ModelA <- ifelse(predictA>i,1,0)
  # Create Confusion Matrix
  conf_mat <- as.matrix(table(Actual = testing$spam, Predicted = testing$predict_ModelA))
  # Sensitivity & Specificity
  sen <- rbind(sen, caret::recall(conf_mat))
  spec <- rbind(spec, caret::precision(conf_mat))
}
sen_spec <- cbind(sen_spec, sen,spec)
colnames(sen_spec) <-  c('threshold', 'sensitivity', 'specificity')
{plot(sen_spec$threshold, sen_spec$sensitivity, xlab = 'Threshold', ylab = 'Sensitivity/Specifictiy', col = 'red')
points(sen_spec$threshold, sen_spec$specificity, col = 'blue')
legend(0.4,0.90,legend = c('sensitivty', 'specificity'), col = c('red','blue'), lty = c(1,1))}
```

### Use the new threshold values to predict from Models A
```{r}
# For Model A we use a threshold of 0.45
# Use the fitted model to predict
testing$predict_ModelA <- ifelse(predictA>0.45,1,0)
```

## Model A (with classification probability 0.45) Diagnostics
### Sensitivity vs Specificity
```{r}
# Create Confusion Matrix
conf_mat <- as.matrix(table(Actual = testing$spam, Predicted = testing$predict_ModelA))
# Sensitivity & Specificity
print(paste('The specificity of Model A is:',caret::precision(conf_mat)))
print(paste('The sensitivity of Model A is:',caret::recall(conf_mat))) 
```

#### Brier Score
```{r}
print(paste('The Brier Score for Model A is:',brier(testing$spam, predictA)))
```


# Model B (Linear Discriminant Analysis)
```{r}
library(MASS)
## Fit the Model with selected features
modelB <- lda(formula,data = training)
## Use the fitted model to predict
predictB <- predict(modelB,testing, type = 'response')
testing$predict_ModelB <- predictB$class
```

## Model B Diagnostics
### Sensitivity vs Specificity
```{r}
# Create Confusion Matrix
conf_mat <- as.matrix(table(Actual = testing$spam, Predicted = testing$predict_ModelB))
print(conf_mat)
# Sensitivity vs Specificity
print(paste('The specificity of Model B is:',caret::precision(conf_mat)))
print(paste('The sensitivity of Model B is:',caret::recall(conf_mat)))
```


#### Plot ROC Curve for Model B and deterimine AUC
```{r}
plot(roc(testing$spam, predictB$posterior[,2], direction = '<'), col = 'red', lwd = 3, main = 'ROC curve for Model B', print.auc = T)
```


## Select the best threshold for Model B - Where sensitivity and specifictiy lines intersect
```{r}
sen_spec <- data.frame(x = seq(0.2,0.8,by = 0.05))
sen <- data.frame()
spec <- data.frame()
for (i in seq(0.2,0.8,by = 0.05)){
  ## Use the fitted model to predict
  testing$predict_ModelB <- ifelse(predictB$posterior[,2]>i,1,0)
  # Create Confusion Matrix
  conf_mat <- as.matrix(table(Actual = testing$spam, Predicted = testing$predict_ModelB))
  # Sensitivity & Specificity
  sen <- rbind(sen, caret::recall(conf_mat))
  spec <- rbind(spec, caret::precision(conf_mat))
}
sen_spec <- cbind(sen_spec, sen,spec)
colnames(sen_spec) <-  c('threshold', 'sensitivity', 'specificity')
{plot(sen_spec$threshold, sen_spec$sensitivity, xlab = 'Threshold', ylab = 'Sensitivity/Specifictiy', col = 'red', ylim = c(0.65,1))
points(sen_spec$threshold, sen_spec$specificity, col = 'blue')
legend(0.2,0.75,legend = c('sensitivty', 'specificity'), col = c('red','blue'), lty = c(1,1))}

```

### Use the new threshold values to predict from Model B
```{r}
# For Model B we use a threshold of 0.30
# Use the fitted model to predict
testing$predict_ModelB <- ifelse(predictB$posterior[,2]>0.30,1,0)
```

## Model B (with classification probability 0.30) Diagnostics
### Sensitivity vs Specificty
```{r}
# Create Confusion Matrix
conf_mat <- as.matrix(table(Actual = testing$spam, Predicted = testing$predict_ModelB))
# Sensitivity & Specificity
sen <- rbind(sen, recall(conf_mat))
spec <- rbind(spec, precision(conf_mat))
print(paste('The specificity of Model B is:',caret::precision(conf_mat)))
print(paste('The sensitivity of Model B is:',caret::recall(conf_mat))) 

```


### Brier Score
```{r}
print(paste('The Brier Score for Model B is:',brier(testing$spam, predictB$posterior[,2])))
```

# Comparing Model A using probit regression
```{r, show = FALSE}
modelA3 <- glm(formula,data = training, family=binomial(link="probit"))

## Use the fitted model to predict
predictA <- predict(modelA3,testing, type = 'response')
testing$predict_ModelA <- ifelse(predictA>0.5,1,0)
```

## Model A (with probit regression) Diagnostics
### Sensitivity vs Specificity
```{r}
# Create Confusion Matrix
conf_mat <- as.matrix(table(Actual = testing$spam, Predicted = testing$predict_ModelA))
print(conf_mat)
# Sensitivity vs Specificity
print(paste('The specificity of model A (probit regression) is:',caret::precision(conf_mat)))
print(paste('The sensitivity of model A (probit regression) is:',caret::recall(conf_mat)))
```

### Plot ROC Curve for Model A and deterimine AUC
```{r}
plot(roc(testing$spam, predictA, direction = '<'), col = 'red', lwd = 3, main = 'ROC curve for Model A (probit regression)', print.auc = T)
```


## Select best threshold for model - Where sensitivity and specifictiy lines intersect
```{r}
sen_spec <- data.frame(x = seq(0.2,0.8,by = 0.05))
sen <- data.frame()
spec <- data.frame()
for (i in seq(0.2,0.8,by = 0.05)){
  ## Use the fitted model to predict
  testing$predict_ModelA <- ifelse(predictA>i,1,0)
  # Create Confusion Matrix
  conf_mat <- as.matrix(table(Actual = testing$spam, Predicted = testing$predict_ModelA))
  # Sensitivity & Specificity
  sen <- rbind(sen, caret::recall(conf_mat))
  spec <- rbind(spec, caret::precision(conf_mat))
}
sen_spec <- cbind(sen_spec, sen,spec)
colnames(sen_spec) <-  c('threshold', 'sensitivity', 'specificity')
{plot(sen_spec$threshold, sen_spec$sensitivity, xlab = 'Threshold', ylab = 'Sensitivity/Specifictiy', col = 'red')
points(sen_spec$threshold, sen_spec$specificity, col = 'blue')
legend(0.4,0.90,legend = c('sensitivty', 'specificity'), col = c('red','blue'), lty = c(1,1))}
```

### Use the new threshold values to predict from Models A
```{r}
# For Model A we use a threshold of 0.45
# Use the fitted model to predict
testing$predict_ModelA <- ifelse(predictA>0.45,1,0)
```

## Model A (with classification probability 0.45) Diagnostics
### Sensitivity vs Specificity
```{r}
# Create Confusion Matrix
conf_mat <- as.matrix(table(Actual = testing$spam, Predicted = testing$predict_ModelA))
# Sensitivity & Specificity
print(paste('The specificity of Model A (probit regression) is:',caret::precision(conf_mat)))
print(paste('The sensitivity of Model A (probit regression) is:',caret::recall(conf_mat))) 
```

#### Brier Score
```{r}
print(paste('The Brier Score for Model A (probit regression) is:',brier(testing$spam, predictA)))
```


